{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from main import time_format\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = 'imported_images'\n",
    "logs_folder = 'imported_logs'\n",
    "scripts_folder = 'imported_scripts'\n",
    "runs_folder = '../Neural_Lithography'\n",
    "\n",
    "runs = [os.path.join(runs_folder, directory) for directory in os.listdir(runs_folder) if 'single_file' in directory and os.path.isdir(os.path.join(runs_folder, directory))]\n",
    "for run in runs:\n",
    "    for file in os.listdir(run):\n",
    "        if '.png' in file:\n",
    "            shutil.copyfile(os.path.join(run, file), os.path.join(images_folder, file))\n",
    "        if '.log' in file:\n",
    "            shutil.copyfile(os.path.join(run, file), os.path.join(logs_folder, file))\n",
    "            \n",
    "\n",
    "def merge_images(run:str):\n",
    "    folder_1 = 'imported_images'\n",
    "    folder_2 = 'report_images'\n",
    "    files = sorted([os.path.join(folder_1, file) for file in os.listdir(folder_1) if run in file], key = lambda x: 0 if 'train' in x else 1)\n",
    "    # print(f'{run=}', end=' ')\n",
    "    if len(files) != 2:\n",
    "        # print(f'abort {len(files)=}')\n",
    "        return False\n",
    "    else:\n",
    "        ...\n",
    "        # print()\n",
    "    images = [Image.open(x) for x in files]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        new_im.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    \n",
    "    new_im.save(os.path.join(folder_2, f'single_file_{run}.png'))\n",
    "    return True\n",
    "\n",
    "runs_list = []\n",
    "for r in runs:\n",
    "    parts = r.split('_')\n",
    "    r = parts[-2] + '_' +  parts[-1]\n",
    "    runs_list.append(r)\n",
    "\n",
    "runs_list.sort()\n",
    "\n",
    "text = ''\n",
    "for I, run in enumerate(runs_list):\n",
    "    if merge_images(run):\n",
    "        template = '''\n",
    "### Run {I}: {run}\n",
    "- model: {model}\n",
    "- epochs: {epochs}\n",
    "- learning rate: {learning_rate}\n",
    "- train {loss_train}\n",
    "- optimization {loss_optimization}\n",
    "\n",
    "![](report_images/single_file_{run}.png)\n",
    "\n",
    "        '''\n",
    "\n",
    "        def get_index(rows, string): \n",
    "            for i in range(len(rows)):\n",
    "                if string in rows[i]:\n",
    "                    return i\n",
    "            raise ValueError(f'{string} not found in rows of file {run}')\n",
    "\n",
    "        with open(os.path.join(logs_folder, f'logfile_{run}.log'), 'r') as file:\n",
    "            rows = file.readlines()\n",
    "            model = rows[get_index(rows, 'model')].split(':')[1].replace('\"', '').replace(',', '').replace(' ','').replace('\\n', '')\n",
    "            epochs = rows[get_index(rows, 'epoch')].split(':')[1].replace(',', '').replace(' ','').replace('\\n', '')\n",
    "            learning_rate = rows[get_index(rows, 'model_lr')].split(':')[1].replace(',', '').replace(' ','').replace('\\n', '')\n",
    "            try:\n",
    "                loss_train = rows[get_index(rows, ' - train')].split(' ')[-1].replace('\\n', '')\n",
    "            except:\n",
    "                loss_train = rows[get_index(rows, 'loss function for train')].split(' ')[-1].replace('\\n', '')\n",
    "            \n",
    "            try:\n",
    "                loss_optimization = rows[get_index(rows, ' - optim')].split(' ')[-1].replace('\\n', '')\n",
    "            except:\n",
    "                loss_optimization = rows[get_index(rows, 'mask with loss')].split(' ')[-1].replace('\\n', '')\n",
    "\n",
    "        text += template.format(\n",
    "            I=I,\n",
    "            run = run,\n",
    "            model = model,\n",
    "            epochs = epochs,\n",
    "            learning_rate = learning_rate,\n",
    "            loss_train = loss_train,\n",
    "            loss_optimization = loss_optimization) \n",
    "        \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The experiments with Neural Litho from [Neural Lithography: Close the Design-to-Manufacturing Gap in\n",
    "Computational Optics with a ’Real2Sim’ Learned Photolithography\n",
    "Simulator](https://arxiv.org/pdf/2309.17343) of the neural network started with experiments with the original code from this [repository](https://github.com/Neural-Litho/Neural_Lithography/tree/main). The code was required to be adapted for our case.\n",
    "\n",
    "The main difference was, that the code from the paper was used to optimize holographic optical element using the litho digital twin and optical system to compute loss. In our case we want to optimize mask, using the litho digital twin. To do that I needed to get rid of code responsible for the optical system, conversion of stepped mask to continuous mask, which meant getting rig of softmax-gumbel trick, and also the training, that is no longer takes into account the optical loss, but the litho loss only.\n",
    "\n",
    "The set of different experiments were performed to train the model as well as optimize the mask. As a dataset I used the masks, where transmission looked like cones, and the output resist shape simulated in Dr.Litho. Below the results of the experiments are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt - working with the original code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and optimization results\n",
    "\n",
    "\n",
    "### Run 0: 2024-07-25_10-35-28\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.01\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-25_10-35-28.png)\n",
    "\n",
    "        \n",
    "### Run 2: 2024-07-25_12-43-00\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.01\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-25_12-43-00.png)\n",
    "\n",
    "        \n",
    "### Run 3: 2024-07-25_13-14-18\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.01\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-25_13-14-18.png)\n",
    "\n",
    "        \n",
    "### Run 4: 2024-07-25_13-43-43\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-25_13-43-43.png)\n",
    "\n",
    "        \n",
    "### Run 5: 2024-07-25_14-11-59\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-25_14-11-59.png)\n",
    "\n",
    "        \n",
    "### Run 6: 2024-07-25_16-42-28\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-25_16-42-28.png)\n",
    "\n",
    "        \n",
    "### Run 7: 2024-07-27_21-55-06\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-27_21-55-06.png)\n",
    "\n",
    "        \n",
    "### Run 8: 2024-07-27_23-02-42\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-27_23-02-42.png)\n",
    "\n",
    "        \n",
    "### Run 9: 2024-07-27_23-17-18\n",
    "A promising result. What was done? \n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-27_23-17-18.png)\n",
    "\n",
    "        \n",
    "### Run 10: 2024-07-28_00-02-26\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_00-02-26.png)\n",
    "\n",
    "        \n",
    "### Run 11: 2024-07-28_00-27-20\n",
    "- model: fno\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_00-27-20.png)\n",
    "\n",
    "        \n",
    "### Run 12: 2024-07-28_00-55-10\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_00-55-10.png)\n",
    "\n",
    "        \n",
    "### Run 14: 2024-07-28_01-23-31\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_01-23-31.png)\n",
    "\n",
    "        \n",
    "### Run 18: 2024-07-28_13-50-25\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.01\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_13-50-25.png)\n",
    "\n",
    "        \n",
    "### Run 19: 2024-07-28_13-55-01\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_13-55-01.png)\n",
    "\n",
    "        \n",
    "### Run 20: 2024-07-28_14-25-24\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_14-25-24.png)\n",
    "\n",
    "        \n",
    "### Run 23: 2024-07-28_17-01-55\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.0001\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_17-01-55.png)\n",
    "\n",
    "        \n",
    "### Run 24: 2024-07-28_17-08-24\n",
    "- model: pbl3d\n",
    "- epochs: 100\n",
    "- learning rate: 0.01\n",
    "- train mse_loss\n",
    "- optimization mse_loss\n",
    "\n",
    "![](report_images/single_file_2024-07-28_17-08-24.png)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second attempt - Creating MLOps pipeline and creating own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Run 0: 2024.07.28_22:19:07\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 10\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.28_22:19:07/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 0.1\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.28_22:19:07/optimization.png)\n",
      "\n",
      "\n",
      "### Run 1: 2024.07.28_22:51:07\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 10\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.28_22:51:07/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 0.1\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.28_22:51:07/optimization.png)\n",
      "\n",
      "\n",
      "### Run 2: 2024.07.28_23:50:48\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 50\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.28_23:50:48/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 0.1\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.28_23:50:48/optimization.png)\n",
      "\n",
      "\n",
      "### Run 3: 2024.07.29_00:00:37\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 50\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:00:37/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 0.1\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:00:37/optimization.png)\n",
      "\n",
      "\n",
      "### Run 4: 2024.07.29_00:27:02\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 50\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:27:02/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 0.1\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:27:02/optimization.png)\n",
      "\n",
      "\n",
      "### Run 5: 2024.07.29_00:36:05\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 50\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:36:05/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 0.1\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:36:05/optimization.png)\n",
      "\n",
      "\n",
      "### Run 6: 2024.07.29_00:43:14\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 50\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:43:14/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 10\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:43:14/optimization.png)\n",
      "\n",
      "\n",
      "### Run 7: 2024.07.29_00:45:40\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 50\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: BCELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:45:40/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 10\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: BCELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_00:45:40/optimization.png)\n",
      "\n",
      "\n",
      "### Run 8: 2024.07.29_11:21:05\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 10\n",
      "- batch_size: 50\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_11:21:05/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 10\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_11:21:05/optimization.png)\n",
      "\n",
      "\n",
      "### Run 9: 2024.07.29_11:25:25\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 1\n",
      "- batch_size: 10\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_11:25:25/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 10\n",
      "- num_epochs: 1000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_11:25:25/optimization.png)\n",
      "\n",
      "\n",
      "### Run 10: 2024.07.29_15:13:44\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 1\n",
      "- batch_size: 10\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_15:13:44/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 10\n",
      "- num_epochs: 10000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_15:13:44/optimization.png)\n",
      "\n",
      "\n",
      "### Run 11: 2024.07.29_18:38:41\n",
      "\n",
      "Training parameters:\n",
      "- plotting_interval: 1\n",
      "- batch_size: 10\n",
      "- split_percent: 0.1\n",
      "- shuffle_dataset: False\n",
      "- learning_rate: 0.0001\n",
      "- num_epochs: 1000\n",
      "- early_stopping_patience: 5\n",
      "- optimizer: <class 'torch.optim.adam.Adam'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_18:38:41/training.png)\n",
      "\n",
      "Optimization parameters:\n",
      "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
      "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
      "- plotting_interval: 100\n",
      "- learning_rate: 1\n",
      "- num_epochs: 10000\n",
      "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "- loss_function: MSELoss()\n",
      "\n",
      "\n",
      "![](model_runs/run_2024.07.29_18:38:41/optimization.png)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder = 'model_runs'\n",
    "valid_runs = []\n",
    "for run in os.listdir(folder):\n",
    "    run_folder = os.path.join(folder, run)\n",
    "    if len([x for x in os.listdir(run_folder) if '.png' in x]) > 1:\n",
    "        valid_runs.append(run_folder)\n",
    "\n",
    "valid_runs.sort()\n",
    "# print(*valid_runs, sep='\\n')\n",
    "\n",
    "def json_to_md(js:dict):\n",
    "    text = ''\n",
    "    for key, val in js.items():\n",
    "        text += f'- {key}: {val}\\n'\n",
    "\n",
    "    return text\n",
    "\n",
    "def merge_images(run:str):\n",
    "    folder_1 = 'model_runs'\n",
    "    folder_2 = 'report_image_2'\n",
    "    files = [file for file in os.listdir(os.path.join(folder_1, run)) if '.png' in file]\n",
    "    files = sorted(files, key=lambda x: 0 if 'training' in x else 1)\n",
    "    images = [Image.open(x) for x in files]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        new_im.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    \n",
    "    new_im.save(os.path.join(folder_2, f'{run}.png'))\n",
    "    return True\n",
    "\n",
    "template = '''\n",
    "### Run {I}: {run}\n",
    "\n",
    "Training parameters:\n",
    "{training_parameters}\n",
    "\n",
    "![](model_runs/run_{run}/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "{optimization_parameters}\n",
    "\n",
    "![](model_runs/run_{run}/optimization.png)\n",
    "\n",
    "'''\n",
    "\n",
    "text = ''\n",
    "for I, run in enumerate(valid_runs):\n",
    "    with open(os.path.join(run, 'results.json'), 'r') as file:\n",
    "        js = json.load(file)\n",
    "\n",
    "    txt = template.format(\n",
    "        I = I,\n",
    "        run = js['time'],\n",
    "        training_parameters = json_to_md(js['training']['parameters']),\n",
    "        optimization_parameters = json_to_md(js['optimization']['parameters'])\n",
    "        )\n",
    "    text += txt\n",
    "    # break\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Run 0: 2024.07.28_22:19:07\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 10\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.28_22:19:07/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 0.1\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.28_22:19:07/optimization.png)\n",
    "\n",
    "\n",
    "### Run 1: 2024.07.28_22:51:07\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 10\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.28_22:51:07/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 0.1\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.28_22:51:07/optimization.png)\n",
    "\n",
    "\n",
    "### Run 2: 2024.07.28_23:50:48\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 50\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.28_23:50:48/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 0.1\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.28_23:50:48/optimization.png)\n",
    "\n",
    "\n",
    "### Run 3: 2024.07.29_00:00:37\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 50\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:00:37/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 0.1\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:00:37/optimization.png)\n",
    "\n",
    "\n",
    "### Run 4: 2024.07.29_00:27:02\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 50\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:27:02/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 0.1\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:27:02/optimization.png)\n",
    "\n",
    "\n",
    "### Run 5: 2024.07.29_00:36:05\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 50\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:36:05/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 0.1\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:36:05/optimization.png)\n",
    "\n",
    "\n",
    "### Run 6: 2024.07.29_00:43:14\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 50\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:43:14/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 10\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:43:14/optimization.png)\n",
    "\n",
    "\n",
    "### Run 7: 2024.07.29_00:45:40\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 50\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: BCELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:45:40/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 10\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: BCELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_00:45:40/optimization.png)\n",
    "\n",
    "\n",
    "### Run 8: 2024.07.29_11:21:05\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 10\n",
    "- batch_size: 50\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_11:21:05/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 10\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_11:21:05/optimization.png)\n",
    "\n",
    "\n",
    "### Run 9: 2024.07.29_11:25:25\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 1\n",
    "- batch_size: 10\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_11:25:25/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 10\n",
    "- num_epochs: 1000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_11:25:25/optimization.png)\n",
    "\n",
    "\n",
    "### Run 10: 2024.07.29_15:13:44\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 1\n",
    "- batch_size: 10\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_15:13:44/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 10\n",
    "- num_epochs: 10000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_15:13:44/optimization.png)\n",
    "\n",
    "\n",
    "### Run 11: 2024.07.29_18:38:41\n",
    "\n",
    "Training parameters:\n",
    "- plotting_interval: 1\n",
    "- batch_size: 10\n",
    "- split_percent: 0.1\n",
    "- shuffle_dataset: False\n",
    "- learning_rate: 0.0001\n",
    "- num_epochs: 1000\n",
    "- early_stopping_patience: 5\n",
    "- optimizer: <class 'torch.optim.adam.Adam'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_18:38:41/training.png)\n",
    "\n",
    "Optimization parameters:\n",
    "- target_mask_fname: ../Neural_Lithography/data/printed_data/mask/data_0.npy\n",
    "- target_dart_fname: ../Neural_Lithography/data/printed_data/afm/data_0.npy\n",
    "- plotting_interval: 100\n",
    "- learning_rate: 1\n",
    "- num_epochs: 10000\n",
    "- optimizer: <class 'torch.optim.sgd.SGD'>\n",
    "- loss_function: MSELoss()\n",
    "\n",
    "\n",
    "![](model_runs/run_2024.07.29_18:38:41/optimization.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
